# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NhkYhxku51Y8Us5QxWV5ZRzmfmt4UIj6

**Seeding for reproducibility**
"""

# Set seeds for reproducibility
# Reproducibility means that every time we run the code, we get the same results (important in ML/DL experiments)

import random  # Import Python's built-in random module
random.seed(0)  # Set the seed for Python's random functions (like random.shuffle, random.randint)

import numpy as np  # Import NumPy for numerical operations
np.random.seed(0)  # Set the seed for NumPy's random functions (like np.random.rand, np.random.randint)

import tensorflow as tf  # Import TensorFlow for building and training deep learning models
tf.random.set_seed(0)  # Set the seed for TensorFlow's random operations (like weight initialization, dropout)

"""**Importing the dependencies**"""

import os  # Provides functions to interact with the operating system (like reading/writing files)
import json  # Allows working with JSON data (reading/writing JSON files)
from zipfile import ZipFile  # Allows extracting and creating ZIP files
from PIL import Image  # Python Imaging Library, used for opening, manipulating, and saving images

import numpy as np  # Provides numerical operations and array support
import matplotlib.pyplot as plt  # Used for plotting graphs and visualizations
import matplotlib.image as mpimg  # Used for reading and displaying images with Matplotlib
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For real-time image augmentation during training
from tensorflow.keras import layers, models  # To build deep learning models (layers and overall architecture)

!pip install kaggle

# Upload kaggle.json file first
kaggle_credentails = json.load(open("kaggle.json"))

# setup Kaggle API key as environment variables
os.environ['KAGGLE_USERNAME'] = kaggle_credentails["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentails["key"]

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

!ls

# Unzip the downloaded dataset
with ZipFile("plantvillage-dataset.zip", 'r') as zip_ref:
    zip_ref.extractall()

print(os.listdir("plantvillage dataset"))
# Lists all files and folders in the "plantvillage dataset" directory and prints them

print(len(os.listdir("plantvillage dataset/segmented")))
# Counts and prints the number of items (files/folders) in the 'segmented' subfolder

print(os.listdir("plantvillage dataset/segmented")[:5])
# Prints the first 5 items in the 'segmented' folder to preview its contents

print(len(os.listdir("plantvillage dataset/color")))
# Counts and prints the number of items in the 'color' subfolder

print(os.listdir("plantvillage dataset/color")[:5])
# Prints the first 5 items in the 'color' folder to preview its contents

print(len(os.listdir("plantvillage dataset/grayscale")))
# Counts and prints the number of items in the 'grayscale' subfolder

print(os.listdir("plantvillage dataset/grayscale")[:5])
# Prints the first 5 items in the 'grayscale' folder to preview its contents

"""Number of Classes = 38"""

print(len(os.listdir("plantvillage dataset/color/Grape___healthy")))
# Counts and prints the number of images in the "Grape___healthy" folder inside the 'color' subdirectory

print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5])
# Prints the first 5 image filenames in the "Grape___healthy" folder to preview its contents

"""**Data Preprocessing**"""

# Dataset Path
base_dir = 'plantvillage dataset/color'
# Stores the path to the main dataset directory containing color images of plant leaves

image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'
# Stores the full path to a specific plant leaf image in the dataset

# Read the image
img = mpimg.imread(image_path)
# Reads the image file from the given path and stores it as a NumPy array

print(img.shape)
# Prints the dimensions of the image array (height, width, color channels)

# Display the image
plt.imshow(img)
# Displays the image using matplotlib

plt.axis('off')  # Turn off axis numbers
# Hides the x and y axis labels for a cleaner image display

plt.show()
# Renders the image on the screen

image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'
# Stores the full path to a specific plant leaf image in the dataset

# Read the image
img = mpimg.imread(image_path)
# Reads the image file from the given path and stores it as a NumPy array

print(img)
# Prints the raw pixel values of the image array (a 3D array for color images)

# Image Parameters
img_size = 224
# Sets the target size (height and width) to which all images will be resized before feeding into the model

batch_size = 32
# Sets the number of images to process in a single batch during training or validation

"""**Train Test Split**"""

# Image Data Generators
data_gen = ImageDataGenerator(
    rescale=1./255,               # Normalize pixel values from [0, 255] to [0, 1] for faster and stable training
    validation_split=0.2           # Reserve 20% of the data for validation while training the model
)

# Train Generator
train_generator = data_gen.flow_from_directory(
    base_dir,                       # Directory where the training images are stored
    target_size=(img_size, img_size), # Resize all images to (224, 224) as required by the model
    batch_size=batch_size,          # Number of images to yield in each batch
    subset='training',              # Use this subset of the data for training (as defined by validation_split)
    class_mode='categorical'        # Use categorical labels (one-hot encoding) for multi-class classification
)

# Validation Generator
validation_generator = data_gen.flow_from_directory(
    base_dir,                       # Directory where the images are stored
    target_size=(img_size, img_size), # Resize all images to (224, 224) for the model
    batch_size=batch_size,          # Number of images to yield in each batch
    subset='validation',            # Use this subset of the data for validation (20% as defined by validation_split)
    class_mode='categorical'        # Use categorical labels (one-hot encoding) for multi-class classification
)

"""**Convolutional Neural Network**"""

# Model Definition
model = models.Sequential()
# Creates a Sequential model where layers are stacked one after another

model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))
# Adds a 2D convolutional layer with 32 filters of size 3x3, ReLU activation, and input shape (224,224,3) for color images

model.add(layers.MaxPooling2D(2, 2))
# Adds a max pooling layer with pool size 2x2 to reduce spatial dimensions and retain important features

model.add(layers.Conv2D(64, (3, 3), activation='relu'))
# Adds a second convolutional layer with 64 filters of size 3x3 and ReLU activation for deeper feature extraction

model.add(layers.MaxPooling2D(2, 2))
# Adds another max pooling layer to further reduce the spatial size of feature maps

model.add(layers.Flatten())
# Flattens the 2D feature maps into a 1D vector to feed into fully connected (dense) layers

model.add(layers.Dense(256, activation='relu'))
# Adds a fully connected layer with 256 neurons and ReLU activation for learning complex patterns

model.add(layers.Dense(train_generator.num_classes, activation='softmax'))
# Adds the output layer with number of neurons equal to number of classes and softmax activation for multi-class classification

# model summary
model.summary()

# Compile the Model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""**Model training**"""

# Training the Model
history = model.fit(
    train_generator,
    # Uses the training data generator to feed images and labels into the model

    steps_per_epoch=train_generator.samples // batch_size,
    # Number of batches to process in one epoch (total training samples divided by batch size)

    epochs=5,
    # Number of complete passes through the training dataset

    validation_data=validation_generator,
    # Uses the validation data generator to evaluate the model after each epoch

    validation_steps=validation_generator.samples // batch_size
    # Number of batches to process for validation in each epoch (total validation samples divided by batch size)
)

"""**Model Evaluation**"""

# Model Evaluation
print("Evaluating model...")
val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Building a Predictive System**"""

# Function to Load and Preprocess the Image using Pillow
def load_and_preprocess_image(image_path, target_size=(224, 224)):
    # Load the image
    img = Image.open(image_path)
    # Resize the image
    img = img.resize(target_size)
    # Convert the image to a numpy array
    img_array = np.array(img)
    # Add batch dimension
    img_array = np.expand_dims(img_array, axis=0)
    # Scale the image values to [0, 1]
    img_array = img_array.astype('float32') / 255.
    return img_array

# Function to Predict the Class of an Image
def predict_image_class(model, image_path, class_indices):
    preprocessed_img = load_and_preprocess_image(image_path)
    predictions = model.predict(preprocessed_img)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

# Create a mapping from class indices to class names
class_indices = {v: k for k, v in train_generator.class_indices.items()}

class_indices

# saving the class names as json file
json.dump(class_indices, open('class_indices.json', 'w'))

# Example Usage
image_path = '/content/test_apple_black_rot.JPG'
#image_path = '/content/test_blueberry_healthy.jpg'
#image_path = '/content/test_potato_early_blight.jpg'
predicted_class_name = predict_image_class(model, image_path, class_indices)

# Output the result
print("Predicted Class Name:", predicted_class_name)

model.save('plant_disease_prediction_model.h5')